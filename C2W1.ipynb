{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1343550",
   "metadata": {},
   "source": [
    "# Curso 2: Improving Neural Networks\n",
    "## RafaCastle\n",
    "\n",
    "## Semana 1\n",
    "## Hyperparameter tuning, Regularization and Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f811838",
   "metadata": {},
   "source": [
    "## Conjuntos de prueba y de entrenamiento\n",
    "\n",
    "Tomar buenas elecciones al momento de configurar los conjuntos de prueba y entrenamiento para una red neuronal puede hacer una gran diferencia en el desempeño de ésta. \n",
    "\n",
    "Al iniciar una nueva aplicación para una red neuronal es prácticamente imposible adivinar cuales son los mejores hyperparámetros en el primer intento, ya que depende del conjunto de datos, el problema e incluso del ordenador en el cual se creará el modelo. Es por esto que los procedimientos del aprendizaje profundo son en gran medida empíricos.  \n",
    "\n",
    "Generalmente, en conjuntos de datos pequeños los conjuntos de prueba y testeo se dividen en una relación 70-30. Sin embargo en conjuntos con una gran cantidad de datos se suelen hacer divisiones 99-1 para los conjuntos de prueba y testeo. \n",
    "\n",
    "Es tambien importante que la procedencia de los datos sea la misma para los conjuntos de prueba y entrenamiento, no usar bases distintas para entrenar y testear, hacer esto podría llevar a un gran porcentaje de error en el momento de medir la precisión del modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b544407",
   "metadata": {},
   "source": [
    "## Sesgo y varianza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c1f9c0",
   "metadata": {},
   "source": [
    "En general un modelo no debe tener ni varianza ni sesgo alto, en la siguiente imagen se ilustra un ejemplo de un modelo con varianza alta o overfitting a la derecha, un morelo con alto sesgo o underfitting a la izquierda y un modelo apropiado enmedio.\n",
    "\n",
    "![Title](Imágenes/2.2.1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8271caf",
   "metadata": {},
   "source": [
    "En general si se tiene un error en el conjunto de prueba muy alto se considera que el sesgo es alto y si el error del conjunto de prueba es muy alto en relación con el de prueba entonces se considera que se tiene una varianza alta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83215ec",
   "metadata": {},
   "source": [
    "## Regularización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9535f91",
   "metadata": {},
   "source": [
    "Al enfrentarse con un problema de overfitting, una de las primeras cosas a tratar es la regularización. \n",
    "\n",
    "La regularización, para un problema de regresión logística se aplica a la función de pérdida:\n",
    "\n",
    "$$\n",
    "J(w,b) = \\frac{1}{m} \\sum_{j=1}^m L(\\overline{y}^{(i)},y^{(i)}) + \\frac{\\lambda}{2m} ||w||^2\n",
    "$$\n",
    "\n",
    "A esta función se le conoce como regularización $L_2$ (es la más común), mientras que la regularización $L_1$ toma el término $||w||$ en lugar de $||w||^2$, la regularización $L_1$ hace muy pequeño al parámetro $w$. $\\lambda$ es llamado el parámetro de regularización. \n",
    "\n",
    "Para una red neuronal se tiene:\n",
    "\n",
    "$$\n",
    "J(w^{[1]},b^{[1]},...,w^{[L]},b^{[L]}) = \\frac{1}{m} \\sum_{j=1}^m L(\\overline{y}^{(i)},y^{(i)}) + \\frac{\\lambda}{2m} \\sum_{l=1}^L ||w^{[l]}||^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c73ce0d",
   "metadata": {},
   "source": [
    "Donde \n",
    "\n",
    "$$\n",
    " ||w^{[l]}||^2 = \\sum_{i=1}^{n^{[l-1]}} \\sum_{j=1}^{n^{[l]}} (w_{ij}^{[l]})^2\n",
    "$$\n",
    "\n",
    "ya que la matriz $w^{[l]}$ es de dimensión $(n^{[l]},n^{[l-1]})$. Igualmente para el algoritmo de backpropagation, solo se suma el término $\\frac{\\lambda}{m} w^{[l]}$ a la expresión que se tenía de $dw^{[l]}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d74e85",
   "metadata": {},
   "source": [
    "### ¿Por qué la regularización reduce el overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2882848e",
   "metadata": {},
   "source": [
    "Al intentar minimizar la función $J$ regularizada, se harán más pequeños a los valores $w$ mientras más grande sea el valor de $\\lambda$. Por lo que la función de activación $g(z)$ con $z^{[l]}=w^{[l]}a^{[l-1]}+b^{[l]}$ tomará solo los valores más cercanos a 0, donde en general las funciones más clásicas como la de sigmoide o la de la tangente hiperbólica tienen un comportamiento lineal. Así, mientras más grande sea el parámetro $\\lambda$, las capas de la red neuronal se aproximarán más a un ajuste lineal, por muy grande que la red neuronal sea."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c66a9ad",
   "metadata": {},
   "source": [
    "## Regularización dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8f1426",
   "metadata": {},
   "source": [
    "Existe otra técnica de regularización llamada dropout. Supongamos que se tiene una red neuronal como la que se muestra a la izquierda de la siguiente figura, se busca eliminiar varias de las neuronas por lo que se pasa cada una de ellas por una elección aleatoria donde cada una tiene 50\\% de probabilidad de ser eliminadas (la probabilidad puede variar). Por lo que las neuronas con taches son escogidas para eliminarse como se muestra en la figura de la derecha.\n",
    "\n",
    "![Title](Imágenes/2.3.1.png)\n",
    "\n",
    "Resultando una red mucho más pequeña:\n",
    "\n",
    "![Title](Imágenes/2.3.2.png)\n",
    "\n",
    "Así, para cada dato de entrenamiento se tiene un red neuronal más pequeña que la original. \n",
    "\n",
    "Ahora ¿Por qué este método es una regularización? De manera intuitiva al tener una red neuronal más pequeña se tienen menos posibilidades de llegar a resultados complejos, por lo tanto menos probabilidad de hacer overfitting. Otra idea intuitica es la siguiente: Fijémonos en una sola neurona en una cierta capa $l>1$. Para los diferentes ejemplos en el conjunto de entrenamiento la neurona va a ir variando subconjuntos de esos 10 inputs de diferentes maneras. Así es que no puede ponerle mucho peso a un input en particular (aunque realmente sea un input importante) ya que a veces el input fue eliminado y no se tomó en consideración. Resulta un algoritmo muy útil si se quiere hacer un cuchareo..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d6fe15",
   "metadata": {},
   "source": [
    "## Otros métodos de regularización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7287929",
   "metadata": {},
   "source": [
    "Conseguir más datos puede ser una buena forma de reducir el overfitting, si no es posible conseguir más, siempre pueden usarse los datos existentes de manera ingeniosa. Por ejemplo, si se busca entrenar un algoritmo de detección facial pueden girarse las imágenes (espejo) y tomarse como un nuevo ejemplo, así se duplicaría el conjunto de entrenamiento. También pueden hacerse zoom y rotaciones. \n",
    "\n",
    "Estas técnicas no agregan información más valiosa como sería una imágen completamente nueva pero si agregan un poco de información al conjunto.\n",
    "\n",
    "![Title](Imágenes/2.3.3.png)\n",
    "\n",
    "Otra técnica conocida como el early stopping es graficar la función de pérdida vs el error en el conjunto de prueba y tomar el número de iteraciones donde el conjunto de prueba es mínimo. Por lo general los valores de $w$ van creciendo con el número de iteraciones por lo que se toma un valor intermedio de $||w||^2$.\n",
    "\n",
    "![Title](Imágenes/2.3.4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf8145b",
   "metadata": {},
   "source": [
    "Con esto queda claro que al trabajar en un algoritmo de deep learning, se tienen 2 metas que deben ser trabajadas por separado por el simple hecho de que no es posible trabajar en ambas al mismo tiempo.\n",
    "\n",
    " - Optimizar la función de pérdida J\n",
    " - No caer en el overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fccfc90",
   "metadata": {},
   "source": [
    "## Optimización\n",
    "\n",
    "### Normalizando los inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c819cd",
   "metadata": {},
   "source": [
    "En general, los inputs se normalizan para hacer una función de pérdida menos elongada y así localizar el mínimo en menos iteraciones, con un coeficiente de aprendizaje no tan pequeño.\n",
    "\n",
    "![Title](Imágenes/2.3.5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc726f8f",
   "metadata": {},
   "source": [
    "En los siguientes videos se ven 2 conceptos no muy importantes que puden resumirse mucho:\n",
    "\n",
    " - No se deben tener valores de $w$ similares en las capas de una red neuronal muy profunda, ya que los outputs pueden volverse o muy grandes o muy pequeños.\n",
    " - Si una neurona tiene muchos inputs, los pesos deben ser muy pequeños ya que esos inputs se suman de forma $\\sum_{i=1}^n w_i x_i$. Por lo que el valor del input podría volverse muy grande si $n$ es muy grande y los valores de $w_i$ no son pequeños.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c39bed4",
   "metadata": {},
   "source": [
    "## Verificación del gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0d804f",
   "metadata": {},
   "source": [
    "Como algoritmo, backpropagation puede ser complejo de implementar por su gran cantidad de detalles, además muchos bugs pueden ser pasados por alto. Es por esto que surge la idea de verificar el gradiente, de modo que estos errores sean visibles. Veamos la idea.\n",
    "\n",
    "Consideremos una función $J(\\Theta)$ donde $\\Theta$ estará definida como la concatenación de los parámetros de la red, es decir:\n",
    "\n",
    "$$\n",
    "\\Theta = W^{[1]}, b^{[1]},..., W^{[L]}, b^{[L]}\n",
    "$$\n",
    "\n",
    "Análogamente, tomamos:\n",
    "\n",
    "$$\n",
    "d\\Theta = dW^{[1]}, db^{[1]},..., dW^{[L]}, db^{[L]}\n",
    "$$\n",
    "\n",
    "Ahora, si nos fijamos en la gráfica de $J(\\Theta)$ tenemos:\n",
    "\n",
    "![Title](Imágenes/2.4.1.png)\n",
    "\n",
    "Tomemos un punto $\\theta$ en el eje horizontal (suponiendo que es un número real) y un valor pequeño ($\\approx 10^{-4}$) $\\epsilon > 0$, por nociones básicas de cálculo, sabemos que es posible aproximar el valor de la derivada de $J$ en este punto por la ecuación\n",
    "\n",
    "$$\n",
    "\\frac{d}{d \\theta} J(\\theta) \\approx \\frac{J(\\theta + \\epsilon) - J(\\theta - \\epsilon)}{2 \\epsilon}\n",
    "$$\n",
    "\n",
    "![Title](Imágenes/2.4.2.png)\n",
    "\n",
    "De esta manera nos podemos dar una idea aproximada del valor del gradiente en $\\theta$.\n",
    "\n",
    "Ahora tomemos $\\theta \\in R^{n}$ tal que $\\theta = [\\theta_1, \\theta_2, ..., \\theta_n]$. Podemos usar una idea similar para aproximar las derivadas parciales y obtener el gradiente, donde $d\\Theta[i] = \\frac{\\partial J}{\\partial \\theta_i}$:\n",
    "\n",
    "![Title](Imágenes/2.4.3.png)\n",
    "\n",
    "Así se puede aproximar el valor de la parcial de $J$ con respecto a alguno de los parámetros $\\theta_i$. El tamaño de la diferencia entre el lado derecho de la ecuación y el izquierdo nos dirá si el gradiente se está definiendo correctamente. Denominemos a los valores del lado derecho como $d\\Theta_{app} [i]$, así, si el valor:\n",
    "\n",
    "$$\n",
    "\\frac{||\\Theta_{app} -  d\\Theta||}{||\\Theta_{app}|| + ||d\\Theta||}\n",
    "$$\n",
    "\n",
    "es del mismo orden de magnitud o menor al de $\\epsilon$, entonces se considera que el gradiente se está iterando correctamente, de lo contrario seguramente hay un bug que corregir. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
