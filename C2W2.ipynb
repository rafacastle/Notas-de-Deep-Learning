{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f1b76c6",
   "metadata": {},
   "source": [
    "# Curso 2: Improving Neural Networks\n",
    "## RafaCastle\n",
    "\n",
    "## Semana 2\n",
    "## Mini-Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ce1aa1",
   "metadata": {},
   "source": [
    "Es posible agrupar el conjunto de entrenamiento, supongamos que se tiene un conjunto $X$ de dimensión $(n,m)$ y un conjunto $Y$ de dimensión $(1,m)$ tal que:\n",
    "\n",
    "$$\n",
    "X = \\left[ x^{(1)}, x^{(2)}, ..., x^{(m)}\\right] \\hspace{1cm} Y = \\left[y^{(1)}, y^{(2)}, ..., y^{(m)}\\right]\n",
    "$$\n",
    "\n",
    "Supongamos que $m$ es muy grande, entonces es práctico definir conjuntos $X^{\\{ i\\}}$ y $Y^{\\{ i\\}}$ que contengan conjuntos pequeños de datos, por ejemplo mil datos cada uno. De modo que:\n",
    "\n",
    "$$\n",
    "X^{\\{ 1\\}} = [x^{(1)}, x^{(2)}, ..., x^{(1,000)}] ,\\hspace{0.3cm} X^{\\{ 2\\}} = [x^{(1,001)}, x^{(1,002)}, ..., x^{(2,000)}], \\hspace{0.3cm} ...\n",
    "$$\n",
    "\n",
    "(análogo para $Y^{\\{ i\\}}$) Se denomina al conjunto minibatch $t$ como $X^{\\{ t\\}},Y^{\\{ t\\}}$. Así, es posible ejecutar la propagación forward para el minibatch $t$ como:\n",
    "\n",
    "$$\n",
    "Z^{[1]} = W^{[1]} X^{\\{ t\\}} + b^{[1]}\n",
    "$$\n",
    "\n",
    "$$\n",
    "A^{[1]} = g^{[1]}(Z^{[1]})\n",
    "$$\n",
    "\n",
    "La función de pérdida $J^{\\{ t\\}}$ también se implementa en este algoritmo tomando en cuenta cambiar $m=1,000$ ya que solo se están tomando mil datos del conjunto de prueba, análogamente se puede implementar la propagación backward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42231933",
   "metadata": {},
   "source": [
    "Al graficar la función $J$ usando minibatch, se tiene una diferencia notable al comparar con el método tradicional:\n",
    "\n",
    "![Title](Imágenes/2.4.4.png)\n",
    "\n",
    "Es posible tomar distintos tamaños de minibatch, siendo el más chico 1, es decir que cada dato del conjunto es en sí mismo un minibatch. Este método es denominado estocástico y por lo general no va a converger para un valor mínimo de $J$ por lo que no es recomendable. Al tomar un tamaño de minibatch igual a $m$ simplemente regresamos al método convencional, por lo que en general se recomienda escoger un valor entre 1 y $m$. En la siguiente figura se muestra en morado el método estocástico, en azúl el método tradicional y en verde un minibatch intermedio, todos los métodos buscan llegar al mínimo de $J$ de distinta manera y aunque en cada iteración el método tradicional apunta siempre en dirección correcta, su implementación puede resultar poco práctica. \n",
    "\n",
    "![Title](Imágenes/2.4.5.png)\n",
    "\n",
    "Se tienen las siguientes guías para escoger el tamaño de los minibatch:\n",
    "\n",
    " - Si el conjunto de entrenamiento es pequeño se debe escoger el método tradicional\n",
    " - Si el conjunto es grande se escogen potencias de $2$: $2^2,2^3,...$\n",
    " - Asegurarse que la computadora que se utiliza pueda manejar el tamaño del minibatch escogido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d8d383",
   "metadata": {},
   "source": [
    "## Algoritmos de optimización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b999ec",
   "metadata": {},
   "source": [
    "Existen algunos algoritmos que son más rápidos que el gradient descent, para entenderlos es necesario entender primero los promedios exponencialmente ponderados. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a99818f",
   "metadata": {},
   "source": [
    "Supongamos que se tienen los datos de la temperatura promedio de un día en Londres, al graficarlos obtenemos algo como lo siguiente:\n",
    "\n",
    "![Title](Imágenes/2.4.6.png)\n",
    "\n",
    "Si aplicamos la siguiente regla de recursión para todas las temperaturas registradas:\n",
    "\n",
    "$$\n",
    "V_i = 0.9 V_{i-1} + 0.1 \\Theta_i\n",
    "$$\n",
    "\n",
    "con $V_o = 0$, obtenemos una gráfica para los puntos $V_i$ como la que se muestra a continuación:\n",
    "\n",
    "![Title](Imágenes/2.4.7.png)\n",
    "\n",
    "A estos valores se les llama el promedio exponencialmente ponderado. De manera general se define como:\n",
    "\n",
    "$$\n",
    "V_i = \\beta V_{i-1} + (1-\\beta) \\Theta_i\n",
    "$$\n",
    "\n",
    "Mientras más cercano a 1 sea el valor de $\\beta$, la curva se comportará de una manera más suave. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec08d689",
   "metadata": {},
   "source": [
    "Una manera de corregir las aproximaciones de los primeros días sin afectar las de los útlimos es tomar $\\frac{V_i}{1-\\beta^i}$ en lugar de $V_i$ al obtener a $V_{i+1}$. A esto se le conoce como corrección del sesgo.\n",
    "\n",
    "## Gradient descent con momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f729b89",
   "metadata": {},
   "source": [
    "El algoritmo momentum es una modificación al algoritmo gradient descent usando a los promedios exponencialmente ponderados. Supongamos que se tiene un algoritmo minibatch que busca llegar al mínimo de la función de pérdida y su gráfica en curvas de nivel se ve así:\n",
    "\n",
    "![Title](Imágenes/2.4.8.png)\n",
    "\n",
    "En este caso se esperaría que el avance en la dimensión horizontal fuera más rápido para llegar al mínimo en menos operaciones. De esta forma puede computarse (omitiendo su superíndices) $dw$ y $db$ como:\n",
    "\n",
    "$$\n",
    "V_{dw} = \\beta V_{dw} + (1-\\beta) dw \\hspace{1cm} V_{db} = \\beta V_{db} + (1-\\beta) db\n",
    "$$\n",
    "\n",
    "y\n",
    "\n",
    "$$\n",
    "w = w - \\alpha V_{dw} \\hspace{1cm} b = b - \\alpha V_{db}\n",
    "$$\n",
    "\n",
    "De esta manera se suavizan los pasos que da el algoritmo gradient descent como se mostró en las gráficas de los promedios exponencialmente ponderados .\n",
    "\n",
    "![Title](Imágenes/2.4.9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baac98f",
   "metadata": {},
   "source": [
    "## RMS prop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa77c818",
   "metadata": {},
   "source": [
    "Existe otro algoritmo llamado RMS prop que también puede acelerar el algoditmo de gradient descent. EL algoritmo se resume a:\n",
    "\n",
    "$$\n",
    "S_{dw} = \\beta S_{dw} + (1-\\beta) dw^2 \\hspace{1cm} S_{db} = \\beta S_{db} + (1-\\beta) db^2\n",
    "$$\n",
    "\n",
    "y\n",
    "\n",
    "$$\n",
    "w = w - \\alpha \\frac{dw}{\\sqrt{S_{dw}}} \\hspace{1cm} b = b - \\alpha \\frac{db}{\\sqrt{S_{db}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb48997",
   "metadata": {},
   "source": [
    "## Algoritmo de optimización Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3452c95a",
   "metadata": {},
   "source": [
    "El algoritmo de Adam mezcla a los algoritmos anteriores de la forma:\n",
    "    \n",
    "$$\n",
    "w = w - \\alpha \\frac{dw}{\\sqrt{V_{dw}}} \\hspace{1cm} b = b - \\alpha \\frac{db}{\\sqrt{V_{db}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c30186d",
   "metadata": {},
   "source": [
    "## Decaimiento del coeficiente de aprendizaje"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5098d8",
   "metadata": {},
   "source": [
    "Supongamos que se tiene un algortimo minibatch y no se logra converger tras muchas iteraciones:\n",
    "\n",
    "![Title](Imágenes/2.4.10.png)\n",
    "\n",
    "Esto puede deberse a que el coeficiente $\\alpha$ es muy grande. Sin embargo hacerlo más pequeño puede ocasionar que el algoritmo tarde demasiado en converger. Para este caso la mejor opción sería tener un algoritmo con un coeficiente de aprendizaje muy grande en sus primeros pasos pero que conforme se acerque al mínimo fuera disminuyendo. De modo que se tuviera una ruta cómo la que se muestra a continuación:\n",
    "\n",
    "![Title](Imágenes/2.4.11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f96760",
   "metadata": {},
   "source": [
    "Para implementar este algoritmo se define el valor de alfa para cada iteración cómo:\n",
    "\n",
    "$$\n",
    "\\alpha_i = \\frac{1}{1+ \\gamma \\times i}\\alpha_o\n",
    "$$\n",
    "\n",
    "Donde $i$ es el número de iteración, $\\alpha_o$ es un coeficiente de aprendizaje inicial y $\\gamma$ es el coeficiente de decamiento (que es en sí mismo un hyper-parámetro). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f35e84",
   "metadata": {},
   "source": [
    "Existen otros métodos como:\n",
    "\n",
    "$$\n",
    "\\alpha_i = B^i \\alpha_o \n",
    "$$\n",
    "\n",
    "con $B$ menor a 1. U otro método como:\n",
    "\n",
    "$$\n",
    "\\alpha_i = \\frac{k}{\\sqrt{i}} \\alpha_o \n",
    "$$\n",
    "\n",
    "Con $k$ alguna constante positiva."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4f3d8ff",
   "metadata": {},
   "source": [
    "## El problema del óptimo local\n",
    "\n",
    "En la figura de la izquierda se muestra un diagrama donde un algoritmo puede fácilmente quedar atascado en uno de los mínimos locales que se muestran y no converger en el mínimo global de la función $J$. En la figura de la derecha se muestra una función que tiene un punto que es un mínimo si se grafican una dimensión contra la función $J$ pero un máximo si se grafica la otra. De cualquier modo la derivada en ambos es 0.\n",
    "\n",
    "![Title](Imágenes/2.4.12.png)\n",
    "\n",
    "Aunado a estos obstáculos se pueden también tener funciones que tarden mucho en converger. Como la que se muestra a continuación: \n",
    "\n",
    "![Title](Imágenes/2.4.13.png)\n",
    "\n",
    "Todas estas funciones muestran dificultados para entrenar un algormitmo de aprendizaje pero com las herramientas que se aprendieron en este notebook es posible atacarlas, por ejemplo usando un aldoritmo Adam. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
