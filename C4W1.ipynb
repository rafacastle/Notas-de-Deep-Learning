{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68895dcb",
   "metadata": {},
   "source": [
    "# Curso 4: Improving Neural Networks\n",
    "## RafaCastle\n",
    "\n",
    "## Semana 1 Redes Neuronales Convolucionales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153dc9ca",
   "metadata": {},
   "source": [
    "Existe una rama de la inteligencia artificail llamada la visión computacional, esta rama trata de interpretar el mundo visual por medio de imágenes. \n",
    "\n",
    "Existen diferentes usos para la visión computacional, cómo los que se muestran en la figura.\n",
    "\n",
    "![Title](Imágenes/4.1.1.png)\n",
    "\n",
    "Uno de los principales retos de la visión computacional es el de interpretar imágenes grandes, es decir, con una gran cantidad de pixeles. Supongamos que tenemos una imágen de mil por mil pixeles, en este caso tendríamos 3 millones de pixeles ya que hay 3 capas de colores. Supongamos que queremos darle eta imágen como input $x$ a una red neuronal. En ese caso, si la red tiene mil neuronas en la primera capa, la matriz de parámetros $W^{[1]}$ tendría 3 mil millones de entradas, ya que sería de dimensión 3 millones por mil. Con una matriz de parámetros tan grande, sería difícil obtener un conjunto de datos de entrenamiento lo suficientemente grande como para no tener un overfitting. Para resolver este tipo de problemas se necesita una red neuronal convolucional. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb6c655",
   "metadata": {},
   "source": [
    "## ¿En qué consiste una red neuronal convolucional?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900b8441",
   "metadata": {},
   "source": [
    "Las redes neuronales convolucionales obtienen su nombre a partir de una operación. Para describir el comportamiento de la operación convolucional, vale la pena poner el ejemplo de detección de líneas en una imágen. Supongamos que se busca detectar las líneas (verticales y horizontales) en una imágen cómo la que se muestra a continuación:\n",
    "\n",
    "![Title](Imágenes/4.1.2.png)\n",
    "\n",
    "En una imágen en blanco y negro, se puede representar la briillantez de los pixeles con una matriz. Supongamos que se tiene una imágen de $64 \\times 64$ cómo la que se muestra a continuación:\n",
    "\n",
    "![Title](Imágenes/4.1.3.png)\n",
    "\n",
    "Para detectar a las líneas verticales en la imágen, se hace una multiplicación convolucional con otra matriz que denominaremos filtro (también llamada núcleo):\n",
    "\n",
    "![Title](Imágenes/4.1.4.png)\n",
    "\n",
    "Esta operación da como resultado una matriz de $4 \\times 4$, cuyas entradas siguen la siguiente lógica:\n",
    "\n",
    "![Title](Imágenes/4.1.5.png)\n",
    "\n",
    "La matriz filtro se multiplica por una sub matriz de $3 \\times 3$ dentro de la matriz asociada a la imágen. Dependiendo de la posición en la matríz resultado se mueve la matriz filtro dentro de la matriz imágen y se llega a un resultado final. Dado que solo hay 4 posiciones diferentes en cada dimensión, la matriz resultado termina siendo de $4 \\times 4$.\n",
    "\n",
    "Entonces, ¿cómo es que esta operación detecta líneas verticales? veamos el siguiente ejemplo\n",
    "\n",
    "![Title](Imágenes/4.1.6.png)\n",
    "\n",
    "Lo que nos dice esta operación de manera intruitiva, es que se detecta un borde enmedio de la imágen, que corresponde a la línea que separa a los dos colores en la imágen original. \n",
    "\n",
    "Se esperaría que la operación detectara las líneas con un poco más de precisión, el algortimo detecta una línea tan gruesa debido a que estamos trabajando con una imágen muy pequeña. Para una imágen con una mayor cantidad de pixeles, la matriz de resultados mostraría una línea intermedia mucho más delgada y definida. Encontrándola con mayor precisión. También cabe mencionar que si se invirtieran los colores la granja de enmedio cambiaría también de color a $-30$.\n",
    "\n",
    "![Title](Imágenes/4.1.7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394f494e",
   "metadata": {},
   "source": [
    "Es también posible detectar ejes horizontales al transponer la matriz:\n",
    "\n",
    "![Title](Imágenes/4.1.8.png)\n",
    "\n",
    "Existen otros filtros que sirven para enfocarse más en los pixeles centrales por ejemplo:\n",
    "\n",
    "![Title](Imágenes/4.1.9.png)\n",
    "\n",
    "Sin embargo, es también posible que los valores no sean computados manualmente, sino aprenderlos. Los valores de la matriz núcleo pueden ser tratados como parámetros y aprender cúales son los mejores con propagación backward. \n",
    "\n",
    "![Title](Imágenes/4.2.1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d98cbcf",
   "metadata": {},
   "source": [
    "Como regla general, si se tiene una matriz asociada a la imágen de $n \\times n$ y una matriz núcleo de $f \\times f$, la matriz resultante tendrá una dimensión de $(n-f+1) \\times (n-f+1)$. Cabe también destacar que los pixeles en las esquinas y en los bordes de la matriz serán utilizados mucho menos a la hora de entrenar a un algoritmo para obtener a los parámetros. Por ejemplo, en la siguiente imágen el cuadro verde es utilizado solo una vez al momento de multiplicar por la matriz filtro, mientras el cuadro rojo es utilizado bastantes veces.\n",
    "\n",
    "![Title](Imágenes/4.2.2.png)\n",
    "\n",
    "La solución a este problema es agregar un borde extra a la matriz original, todos los valores de estas nuevas celdas deben ser 0 por convención. \n",
    "\n",
    "![Title](Imágenes/4.2.3.png)\n",
    "\n",
    "La cantidad de bloques que se le agregen a la matriz original es denominada $p$, en este ejemplo $p=1$, de esta forma terminamos con una matriz original de $(n+2p) \\times (n+2p)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947f50d6",
   "metadata": {},
   "source": [
    "Existe una convolución llamada \"Same\", que consta en obtener una matriz resultante de la misma dimensión que la matriz original. Cabe resaltar que para obtener esta matriz el valor $p$ debe cumplir:\n",
    "\n",
    "$$\n",
    "p = \\frac{f-1}{2}\n",
    "$$\n",
    "\n",
    "Nota que en esta ecuación, $f$ debe ser impar para que $p$ sea un número entero, esto es conveniente ya que las matrices núcleo funcionan mejor cuando tienen un centro bien definido, cosa que solo se dá cuando son marices cuadradas de dimensión impar. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a17d5f",
   "metadata": {},
   "source": [
    "### Convoluciones de paso\n",
    "\n",
    "Existe otra técnica de convolución donde los pasos no son de uno en uno sino de $s$ en $s$. Para $s=2$ tendríamos un caso como el que se ve a continuación:\n",
    "\n",
    "![Title](Imágenes/4.2.4.png)\n",
    "\n",
    "La matriz resultante en un caso como este es de dimensión \n",
    "\n",
    "$$\n",
    "\\left( \\frac{n+2p-f}{s} + 1 \\right) \\times \\left( \\frac{n+2p-f}{s} + 1 \\right)\n",
    "$$\n",
    "\n",
    "Cabe descatar que solo se debe realizar el cálculo cuando la dimensión de la matriz resultante sea un número entero, si el número no es entero se redondeara siempre hacia abajo.\n",
    "\n",
    "### Convoluciones en imágenes a color\n",
    "\n",
    "Las imágenes a color pueden representarse como un tensor de profundidad 3, es decir, las imágenes a color pertenecen a un espacio $R^{m \\times n \\times 3}$ (ya que cualquier color puede descomponerse en una mezcla de rojo, verde y azúl). Por lo que lo filtros para estas imágenes pertenecen a un espacio $R^{m_f \\times n_f \\times 3}$. Sin embargo la matriz resultante pertenece a otro espacio $R^{m_r \\times n_r}$. Cabe resaltar que no siempre se tienen 3 canales, ese número rara vez será diferente a 3, si es el caso, siempre será igual para el tensor de inputs y el de filtros.\n",
    "\n",
    "![Title](Imágenes/4.2.5.png)\n",
    "\n",
    "La manera de obtener las entradas de la matriz resultante es la misma. Se realiza la convolución primero en la capa roja, para cada una de las capas del filtro u luego se suman todos los resultados. Si se quieren detectar, por ejemplo, líneas en la capa roja, la primera matriz del filtro se usa para detectar líneas, por decir horizontales, y las otras 2 matrices del filtro se igualan a 0. Si se quieren detectar en la capa verde entonces la primera y la última matriz deben ser cero y la de enmedio se toma para detectar líneas, y así respectivamente. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084af5d5",
   "metadata": {},
   "source": [
    "Supongamos que buscamos detectar líneas horizontales y verticales al mismo tiempo. En ese caso es posible aplicar 2 filtros y acoplar las matrices resultantes en un tensor como se muestra en la siguiente imágen:\n",
    "\n",
    "![Title](Imágenes/4.2.6.png)\n",
    "\n",
    "Así si se tiene una imágen de dimensión $n \\times m \\times c$ y un filtro de $f \\times g \\times c$. El resultado será un tensor de $(n-f+1) \\times (n-f+1) \\times x$ donde $x$ es el número de filtros que se le aplica a la imágen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058bce6b",
   "metadata": {},
   "source": [
    "Es posible hacer una analogía para entender el funcionamiento de las redes neuronales convolucionales. Podemos ver al tensor que representa a la imágen como la netrada de inputos en una red neuronal, es decir, como $a^{[0]}$. La matriz filtro puede verse como los parámetros $w$. Además podemos obtener el valor $z$ como: \n",
    "\n",
    "$$\n",
    "z = w a + b\n",
    "$$\n",
    "\n",
    "Simplemente al hacer la operación de convolución entre $a^{[0]}$ y $w^{[1]}$ obtenemos la primera parte de $z^{[1]}$ y simplemente al sumar un número real $b_1$ a todas las entradas de la matriz resultante podríamos obtener el valor completo de $z^{[1]}$. Finalmente es posible aplicar una función $g$ a $z^{[1]}$ para obtener el valor de $a$, es decir:\n",
    "\n",
    "$$\n",
    "a^{[1]} = g(z^{[1]})\n",
    "$$\n",
    "\n",
    "Donde $g$ se aplica a todos los valores de la matriz resultante $z^{[1]}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bac5235",
   "metadata": {},
   "source": [
    "Hagamos entonces un resumen de la notación para las redes neuronales convolucionales:\n",
    "\n",
    " - $f^{[l]}$ : Tamaño del filtro en la capa $l$\n",
    " - $p^{[l]}$ : Tamaño del padding en la capa $l$\n",
    " - $s^{[l]}$ : Tamaño del paso en la capa $l$\n",
    " \n",
    " Los inputs de la capa $l$ pueden denotarse como:\n",
    " \n",
    " - $n_H^{[l-1]}$ : Número de entradas en la dimensión horizontal\n",
    " - $n_W^{[l-1]}$ : Número de entradas en la dimensión vertical\n",
    " - $n_C^{[l-1]}$ : Número de canales (generalmente 3)\n",
    " \n",
    "Los outputs de la capa $l$ son:\n",
    "\n",
    " - $n_H^{[l]}$ : Número de entradas en la dimensión horizontal\n",
    " - $n_W^{[l]}$ : Número de entradas en la dimensión vertical\n",
    " - $n_C^{[l]}$ : Número de filtros \n",
    " \n",
    "Donde \n",
    "\n",
    "$$\n",
    "n_H^{[l]} = \\left( \\frac{n_H^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}} + 1 \\right)  \\hspace{0.5cm} y \\hspace{0.5cm} n_W^{[l]} = \\left( \\frac{n_W^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}} + 1 \\right) \n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75cec72",
   "metadata": {},
   "source": [
    "Cabe destacar que la dimensión del filtro en la capa $l$ es $f^{[l]} \\times f^{[l]} \\times n_C^{[l-1]}$, la dimensión de $a^{[l]}$ es $n_H^{[l]} \\times n_W^{[l]} \\times n_C^{[l]}$.\n",
    "\n",
    "Por lo general, el útlimo tensor en la red neuronal se reordena todo en un vector y se hace una regresión logística para obtener un resultado final.\n",
    "\n",
    "### Capas de una red convolucional\n",
    "\n",
    "Existen otros tipos de capas en las redes neuronales convolucionales que se describirán más adelante y si bien una red puede tener solo capas convolucionales, comunmente son una mezcla de distintos tipos de capas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16adc254",
   "metadata": {},
   "source": [
    "### Capa Pooling\n",
    "\n",
    "En una capa pooling, se divide la matriz original en sectores y se toma, por ejemplo, el valor máximo de cada sector (max pooling):\n",
    "\n",
    "![Title](Imágenes/4.2.7.png)\n",
    "\n",
    "Así que en este caso en particular tendríamos una matriz original de $4 \\times 4$, $f = 2$ y $s = 2$. Llegando a una matriz resultante de $2\\times 2$. La intuición detrás de este algoritmo no es del todo justificable, sin embargo en pruebas empíricas da muy buenos resultados, es por esto que es ampliamente usada en redes convolucionales. Cabe destacar también que los sectores en los que se divide la matriz no forzosamente deben tener una interseción vacía. Puede aplicarse el algoritmo igual que lo que se ha visto hasta ahora. El algoritmo pooling puede aplicarse para máximos o promedios en el subconjunto escogido. En este algoritmo no hay parámetros que aprender, solo los hyperparámetros $f$ y $s$.\n",
    "\n",
    "Las capas pooling obtenidas pueden aglomerarse en un solo vector y es posible usar esas entradas en una red neuronal como las vistas en los cursos 1 y 2. A una red neuronal que mezcle así ese tipo de capas en una red se le llama \"fully connected\" y son el tipo de red neuronal más utilizada para la visión computacional."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
