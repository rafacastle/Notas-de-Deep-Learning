{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c859af64",
   "metadata": {},
   "source": [
    "# Curso 1: Neural Networks and Deep Learning\n",
    "## RafaCastle\n",
    "\n",
    "## Semana 2\n",
    "## Clasificación Binaria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd17f7c",
   "metadata": {},
   "source": [
    "Cuando se implementa una red neuronal, existen algunas técnicas que son importantes. Por ejemplo, si se tiene un conjunto de entrenamiento con $m$ datos, no es recomendable procesarlos mediante un for loop. En este curso también se veran conceptos como las propagaciones forward y backward. \n",
    "\n",
    "Para ilustrar estos conceptos se usará la regresión logística, que es un algoritmo para la calsificación binaria. Tomemos un ejemplo de un problema de clasificación binaria. Supongamos que se quiere identificar si en una imagen hay o no un gato. Las imágenes son representadas en las computadoras como se muestra en la imagen de la derecha (descompuestas en 3 colores).\n",
    "\n",
    "![Title](Imágenes/1.2.1.png)\n",
    "\n",
    "Puede reagruparse el contenido de las 3 matrices en un solo vector $X$:\n",
    "\n",
    "$$\n",
    "X = [255,231,...,255,134,...,255,134]\n",
    "$$\n",
    "\n",
    "De modo que el vector $X$ tendría $64 \\times 64 \\times 3$ entradas. Así, en la clasificación binaria, la meta es desarrollar un algoritmo que inpute un vector $X$ (imágen) y que prediga un valor $y$. Tal que $y=0$ si no hay un gato en la imágen y $y = 1$ si sí. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2c945a",
   "metadata": {},
   "source": [
    "Así, el conjunto de entrenamiento será compuesto por vectores: $(x^{(i)}, y^{(i)})$ con $i = 1,...,m$. Podemos definir a la matriz de entrenamiento $X$ como se muestra en la figura:\n",
    "\n",
    "![Title](Imágenes/1.2.2.png)\n",
    "\n",
    "donde $n_x = 64 \\times 64 \\times 3$. También resulta útil almacenar a los vectores $y^{(i)}$ como una matriz de la forma:\n",
    "\n",
    "$$\n",
    "Y = [y^{(1)},y^{(2)},...,y^{(m)}]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab00d3c0",
   "metadata": {},
   "source": [
    "## Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5024230e",
   "metadata": {},
   "source": [
    "Dado un ejemplo $x$, sería útil obtener un valor $\\overline{y} = P(y=1|x)$ que nos dé la probailidad de que en la imágen $x$ haya un gato. Este parámetro se calcula mediante la función sigmoide ($\\sigma$) de la forma:\n",
    "\n",
    "$$\n",
    "\\overline{y} = \\sigma (\\Theta^T x)\n",
    "$$\n",
    "\n",
    "Donde $\\Theta = [\\theta_o, \\theta_1, ..., \\theta_{n_x}]$. Resulta útil definir a los parámetros de la regresión logística de la forma $\\theta_o = b$ y $\\omega = [\\theta_1, \\theta_2, ..., \\theta_{n_x}]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7786bb7a",
   "metadata": {},
   "source": [
    "## Cost function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a654c64b",
   "metadata": {},
   "source": [
    "Para recapitular, la función sigmoide tiene la forma:\n",
    "\n",
    "$$\n",
    "\\sigma (z) = \\frac{1}{1+e^{-z}}\n",
    "$$\n",
    "\n",
    "Así, dado un conjunto $\\{(x^{(1)}, y^{(1)}),(x^{(2)}, y^{(2)}),...,(x^{(m)}, y^{(m)})\\}$, queremos que $\\overline{y}^{(i)} \\approx y^{(i)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509bbbc2",
   "metadata": {},
   "source": [
    "Para saber que tan bién nos estamos aproximando a $y$ desde $\\overline{y}$ utilizamos una función llamada la función de pérdida:\n",
    "\n",
    "$$\n",
    "L(\\overline{y}, y) = \\frac{(\\overline{y} - y)^2}{2}\n",
    "$$\n",
    "\n",
    "Esta función no es comunmente usada en los algoritmos de regresión logística por razones que se discutirán más adelante, en su lugar se utiliza la siguiente expresión:\n",
    "\n",
    "$$\n",
    "L(\\overline{y}, y) = - (y \\log \\overline{y} + (1-y) \\log(1-\\overline{y}))\n",
    "$$\n",
    "\n",
    "Notemos que cuando se sustituye en la función anterior $y=1$ se busca que $\\overline{y}$ sea próximo a 1 para que la funciónde pérdida tenga un valor mínimo, mientras que si $y=0$, $\\overline{y}$ debe ser próximo a 0.\n",
    "\n",
    "De esta manera podemos definir a la cost function como:\n",
    "\n",
    "$$\n",
    "J(\\omega,b) = \\frac{1}{m} \\sum_{i = 1}^{m} L(\\overline{y}^{(i)}, y^{(i)})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7266f5c3",
   "metadata": {},
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c257ad5",
   "metadata": {},
   "source": [
    "Dado que la función de pérdida nos da el error entre la aproximación que nosotros calculamos $(\\overline{y})$ y la real ($y$). Sería idóneo buscar los valores de $\\omega$ y $b$ que minimicen la función $J$. \n",
    "\n",
    "El algoritmo gradient descent va dando valores a $\\omega$ dentro de un loop como se muestra a continuación:\n",
    "\n",
    "$$\n",
    "\\omega = \\omega - \\alpha \\frac{\\partial J}{\\partial \\omega}\n",
    "$$\n",
    "\n",
    "Hasta que se encuentra el valor mínimo de $J$. Donde $\\alpha$ se denomina el coeficiente de aprendizaje. \n",
    "\n",
    "Este algoritmo hace que el valor de $J$ vaya variando como se muestra a continuación:\n",
    "\n",
    "![Title](Imágenes/1.2.3.png)\n",
    "\n",
    "El valor $\\alpha$ hace que los pasos sean más pequeños o más grandes, valores más pequeños serán más precisos pero requerirán de más cálculos, por lo tanto de más poder computacional y más tiempo. Valores grandes harán que el algoritmo dé mayores saltos pero esto puede hacer que nunca converja, por lo que se debe escoger un valor de $\\alpha$ preciso. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb47a29",
   "metadata": {},
   "source": [
    "## Gradient descent para regresión logística"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ea0df6",
   "metadata": {},
   "source": [
    "Para aplicar el algoritmo de gradient descent a la regresión logística se usa in método representado por el siguiente diagrama:\n",
    "\n",
    "![Title](Imágenes/1.2.4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb6c1f7",
   "metadata": {},
   "source": [
    "Se obtiene el valor de $\\overline{y} = a$ a partir del conjunto de prueba y de ahí se obtiene a la función de pérdida. Es claro que los valores de $\\omega$ y $b$ no están dados al inicio pero ese tema se abordará más adelante, por ahora consideremos que los valores iniciales de $\\omega$ y $b$ están dados de manera aleatoria. Para calcularlos obtengamos primero algunos diferenciales importantes (no tomar los diferenciales del lado izquierdo de la ecuación de manera literal, estas expresiones son un abuso de notación pero así están dadas en el curso original, tomémoslo con calma y aceptemos la ecuación como se da a continuación):\n",
    "\n",
    "$$\n",
    "da = \\frac{d L}{da} = -\\frac{y}{a} + \\frac{1-y}{1-a}\n",
    "$$\n",
    "\n",
    "$$\n",
    "dz = \\frac{d L}{dz} = \\frac{d L}{da}\\frac{d a}{dz} = (-\\frac{y}{a} + \\frac{1-y}{1-a})[a(1-a)] = a-y\n",
    "$$\n",
    "\n",
    "$$\n",
    "d\\omega_i = \\frac{d L}{d\\omega_i} = x_i dz\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e2af9c",
   "metadata": {},
   "source": [
    "De esta manera podemos aplicar el algoritmo con los valores:\n",
    "\n",
    "$$\n",
    "\\omega_{i} = \\omega_{i} - \\alpha d\\omega_{i} \\hspace{1cm} b = b - \\alpha db\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
